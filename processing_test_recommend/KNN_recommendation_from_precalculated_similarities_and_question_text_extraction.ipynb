{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import statistics\n",
    "from tqdm import tqdm\n",
    "import math\n",
    "import operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 898 entries, 0 to 897\n",
      "Data columns (total 4 columns):\n",
      "Unnamed: 0             898 non-null int64\n",
      "texts_3000             898 non-null object\n",
      "same_word_list_3000    898 non-null object\n",
      "percent_3000           898 non-null object\n",
      "dtypes: int64(1), object(3)\n",
      "memory usage: 28.1+ KB\n"
     ]
    }
   ],
   "source": [
    "db_3000.info(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>texts_3000</th>\n",
       "      <th>same_word_list_3000</th>\n",
       "      <th>percent_3000</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Указом президента России Бориса Ельцина внесен...</td>\n",
       "      <td>{'отмечать', 'изменение', 'иностранный', 'роль...</td>\n",
       "      <td>71,25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>В Харькове неизвестные изуродовали лицо депута...</td>\n",
       "      <td>{'регион', 'серьезный', 'агентство', 'являться...</td>\n",
       "      <td>72,22222222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Руководитель  следствия по делу  \"Аэрофлота\"  ...</td>\n",
       "      <td>{'ставить', 'ход', 'фирма', 'отказываться', 'с...</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Постоянный экономический рост позволит Китаю к...</td>\n",
       "      <td>{'внутренний', 'момент', 'сфера', 'слово', 'мн...</td>\n",
       "      <td>72,60273973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>В одном из ночных клубов Хмельницкого группа п...</td>\n",
       "      <td>{'отмечать', 'повод', 'смерть', 'свидетель', '...</td>\n",
       "      <td>70,68965517</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                         texts_3000  \\\n",
       "0           0  Указом президента России Бориса Ельцина внесен...   \n",
       "1           1  В Харькове неизвестные изуродовали лицо депута...   \n",
       "2           2  Руководитель  следствия по делу  \"Аэрофлота\"  ...   \n",
       "3           3  Постоянный экономический рост позволит Китаю к...   \n",
       "4           4  В одном из ночных клубов Хмельницкого группа п...   \n",
       "\n",
       "                                 same_word_list_3000 percent_3000  \n",
       "0  {'отмечать', 'изменение', 'иностранный', 'роль...        71,25  \n",
       "1  {'регион', 'серьезный', 'агентство', 'являться...  72,22222222  \n",
       "2  {'ставить', 'ход', 'фирма', 'отказываться', 'с...           74  \n",
       "3  {'внутренний', 'момент', 'сфера', 'слово', 'мн...  72,60273973  \n",
       "4  {'отмечать', 'повод', 'смерть', 'свидетель', '...  70,68965517  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db_3000 = pd.read_csv(\"3000.csv\")\n",
    "db_3000.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>291</th>\n",
       "      <th>292</th>\n",
       "      <th>293</th>\n",
       "      <th>294</th>\n",
       "      <th>295</th>\n",
       "      <th>296</th>\n",
       "      <th>297</th>\n",
       "      <th>298</th>\n",
       "      <th>299</th>\n",
       "      <th>300</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.025718</td>\n",
       "      <td>-0.004776</td>\n",
       "      <td>0.031789</td>\n",
       "      <td>0.018760</td>\n",
       "      <td>-0.015405</td>\n",
       "      <td>-0.078441</td>\n",
       "      <td>-0.002449</td>\n",
       "      <td>-0.008062</td>\n",
       "      <td>-0.001146</td>\n",
       "      <td>0.010007</td>\n",
       "      <td>...</td>\n",
       "      <td>0.017842</td>\n",
       "      <td>-0.041569</td>\n",
       "      <td>0.077341</td>\n",
       "      <td>0.012496</td>\n",
       "      <td>0.049400</td>\n",
       "      <td>-0.037332</td>\n",
       "      <td>0.001658</td>\n",
       "      <td>0.010653</td>\n",
       "      <td>-0.036526</td>\n",
       "      <td>-0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.018746</td>\n",
       "      <td>0.003426</td>\n",
       "      <td>0.020213</td>\n",
       "      <td>0.056091</td>\n",
       "      <td>-0.006876</td>\n",
       "      <td>-0.030144</td>\n",
       "      <td>0.021508</td>\n",
       "      <td>-0.038640</td>\n",
       "      <td>-0.008778</td>\n",
       "      <td>0.014135</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000866</td>\n",
       "      <td>-0.069830</td>\n",
       "      <td>0.107995</td>\n",
       "      <td>0.041295</td>\n",
       "      <td>0.074002</td>\n",
       "      <td>-0.027547</td>\n",
       "      <td>-0.023377</td>\n",
       "      <td>-0.026141</td>\n",
       "      <td>-0.028869</td>\n",
       "      <td>-0.062423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.030954</td>\n",
       "      <td>0.012660</td>\n",
       "      <td>-0.013010</td>\n",
       "      <td>0.058922</td>\n",
       "      <td>-0.015895</td>\n",
       "      <td>-0.004156</td>\n",
       "      <td>0.043479</td>\n",
       "      <td>-0.097470</td>\n",
       "      <td>0.013334</td>\n",
       "      <td>-0.000223</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.012979</td>\n",
       "      <td>-0.054481</td>\n",
       "      <td>0.129445</td>\n",
       "      <td>0.047809</td>\n",
       "      <td>0.064443</td>\n",
       "      <td>-0.009311</td>\n",
       "      <td>-0.068905</td>\n",
       "      <td>-0.063734</td>\n",
       "      <td>-0.017192</td>\n",
       "      <td>-0.050362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.029982</td>\n",
       "      <td>0.046834</td>\n",
       "      <td>-0.016939</td>\n",
       "      <td>0.034865</td>\n",
       "      <td>-0.004499</td>\n",
       "      <td>-0.025411</td>\n",
       "      <td>0.057243</td>\n",
       "      <td>-0.126531</td>\n",
       "      <td>0.015994</td>\n",
       "      <td>-0.012146</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.063004</td>\n",
       "      <td>0.012827</td>\n",
       "      <td>0.101894</td>\n",
       "      <td>0.074595</td>\n",
       "      <td>0.044913</td>\n",
       "      <td>-0.022268</td>\n",
       "      <td>-0.048629</td>\n",
       "      <td>-0.074751</td>\n",
       "      <td>0.018179</td>\n",
       "      <td>-0.035168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.023059</td>\n",
       "      <td>0.052791</td>\n",
       "      <td>-0.031716</td>\n",
       "      <td>0.051026</td>\n",
       "      <td>-0.040494</td>\n",
       "      <td>-0.007667</td>\n",
       "      <td>0.052596</td>\n",
       "      <td>-0.087467</td>\n",
       "      <td>-0.004326</td>\n",
       "      <td>0.018472</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.052820</td>\n",
       "      <td>0.033877</td>\n",
       "      <td>0.062752</td>\n",
       "      <td>0.100702</td>\n",
       "      <td>0.030436</td>\n",
       "      <td>0.018350</td>\n",
       "      <td>-0.031551</td>\n",
       "      <td>-0.050780</td>\n",
       "      <td>0.061213</td>\n",
       "      <td>-0.059490</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 301 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0         1         2         3         4         5         6    \\\n",
       "0  0.025718 -0.004776  0.031789  0.018760 -0.015405 -0.078441 -0.002449   \n",
       "1  0.018746  0.003426  0.020213  0.056091 -0.006876 -0.030144  0.021508   \n",
       "2  0.030954  0.012660 -0.013010  0.058922 -0.015895 -0.004156  0.043479   \n",
       "3  0.029982  0.046834 -0.016939  0.034865 -0.004499 -0.025411  0.057243   \n",
       "4  0.023059  0.052791 -0.031716  0.051026 -0.040494 -0.007667  0.052596   \n",
       "\n",
       "        7         8         9      ...          291       292       293  \\\n",
       "0 -0.008062 -0.001146  0.010007    ...     0.017842 -0.041569  0.077341   \n",
       "1 -0.038640 -0.008778  0.014135    ...     0.000866 -0.069830  0.107995   \n",
       "2 -0.097470  0.013334 -0.000223    ...    -0.012979 -0.054481  0.129445   \n",
       "3 -0.126531  0.015994 -0.012146    ...    -0.063004  0.012827  0.101894   \n",
       "4 -0.087467 -0.004326  0.018472    ...    -0.052820  0.033877  0.062752   \n",
       "\n",
       "        294       295       296       297       298       299       300  \n",
       "0  0.012496  0.049400 -0.037332  0.001658  0.010653 -0.036526 -0.000000  \n",
       "1  0.041295  0.074002 -0.027547 -0.023377 -0.026141 -0.028869 -0.062423  \n",
       "2  0.047809  0.064443 -0.009311 -0.068905 -0.063734 -0.017192 -0.050362  \n",
       "3  0.074595  0.044913 -0.022268 -0.048629 -0.074751  0.018179 -0.035168  \n",
       "4  0.100702  0.030436  0.018350 -0.031551 -0.050780  0.061213 -0.059490  \n",
       "\n",
       "[5 rows x 301 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trigramms_db = pd.read_csv(\"word_db.csv\", header = None)\n",
    "trigramms_db.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "trigramms_list = []\n",
    "with open(\"trigramm_db.txt\", \"r\", encoding = \"utf-8\") as f:\n",
    "    for trig in f.readlines():\n",
    "        trigramms_list.append(trig[:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'и Александр Лукашенко'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trigramms_list[338]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1070, 1070)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(trigramms_db), len(trigramms_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4800312225948592"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def trigramm_recommendation_from_marked_dataset(recommended_text_precalculated_trig_similarity, words_competence_db, debug = False):\n",
    "    with open(recommended_text_precalculated_trig_similarity, \"r\", encoding = \"utf-8\") as f:\n",
    "        trigr_similarity_dict = json.load(f)\n",
    "        whole_text_vocab_recommendation_dict = {}\n",
    "        for trigramm in trigr_similarity_dict.keys():\n",
    "            if debug: print(trigramm, \"==>\", trigr_similarity_dict[trigramm])\n",
    "            understdanding_prob_list = []\n",
    "            if (trigr_similarity_dict[trigramm]):\n",
    "                for trgrm in trigr_similarity_dict[trigramm]:\n",
    "                    assert abs(list(words_competence_db.iloc[trgrm[0][0]])[-1]) == trgrm[2]\n",
    "                    understdanding_prob = list(words_competence_db.iloc[trgrm[0][0]])[-1]\n",
    "                    understdanding_prob_list.append(understdanding_prob)\n",
    "                understdanding_prob_mean = statistics.mean(understdanding_prob_list) \n",
    "                whole_text_vocab_recommendation_dict[trigramm] = understdanding_prob\n",
    "                \n",
    "        positive_understanding_prob = 0\n",
    "        whole_understading_prob = 0 \n",
    "        for trigramm in whole_text_vocab_recommendation_dict.keys():\n",
    "            if debug:print(trigramm , \"===>\", whole_text_vocab_recommendation_dict[trigramm],'\\n')\n",
    "            if (whole_text_vocab_recommendation_dict[trigramm] > 0):\n",
    "                positive_understanding_prob += whole_text_vocab_recommendation_dict[trigramm]\n",
    "                whole_understading_prob += abs(whole_text_vocab_recommendation_dict[trigramm])\n",
    "            elif(whole_text_vocab_recommendation_dict[trigramm] < 0):\n",
    "                whole_understading_prob += abs(whole_text_vocab_recommendation_dict[trigramm])\n",
    "            if debug:print(positive_understanding_prob, whole_understading_prob)\n",
    "        understanding_prob = positive_understanding_prob/whole_understading_prob\n",
    "        return understanding_prob\n",
    "trigramm_recommendation_from_marked_dataset(\"./words_features_json/text_0.json\", trigramms_db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.213510</td>\n",
       "      <td>0.242857</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.024805</td>\n",
       "      <td>0.024805</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.277500</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.138684</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.238462</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3    4         5         6    7\n",
       "0  0.000000  0.000000  0.000000  0.000000  0.0  0.213510  0.242857  0.0\n",
       "1  0.000000  0.000000  0.024805  0.024805  0.0  0.000000  0.277500  0.0\n",
       "2  0.000000  0.066667  0.000000  0.000000  0.0  0.000000  0.250000  1.0\n",
       "3  0.076923  0.000000  0.000000  0.000000  0.0  0.138684  0.200000  1.0\n",
       "4  0.000000  0.071429  0.000000  0.000000  0.0  0.000000  0.238462  1.0"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_db = pd.read_csv(\"sentence_db.csv\", header = None)\n",
    "sentence_db.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6522199313538282"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def sentence_recommendation_from_marked_dataset(recommended_text_precalculated_sentences_similarity, sentence_competence_db, debug = False):\n",
    "    with open(recommended_text_precalculated_sentences_similarity, \"r\", encoding = \"utf-8\") as f:\n",
    "        sentences_similarity_dict = json.load(f)\n",
    "        whole_text_sent_understanding_prob_list = []\n",
    "        for rec_sentence_sentence_index in sentences_similarity_dict.keys():\n",
    "            if debug: print(rec_sentence_sentence_index, \"==>\", sentences_similarity_dict[rec_sentence_sentence_index])\n",
    "            if(sentences_similarity_dict[rec_sentence_sentence_index]):\n",
    "                sum_similarity = 0 \n",
    "                sentence_understanding_similarity_list = []\n",
    "                for similar_sentence_properties in sentences_similarity_dict[rec_sentence_sentence_index]:\n",
    "                    sent_ind= similar_sentence_properties[0]\n",
    "                    marked_understanding = list(sentence_competence_db.iloc[sent_ind])[-1]\n",
    "                    sentence_similarity = similar_sentence_properties[1]\n",
    "                    sum_similarity += sentence_similarity\n",
    "                    sentence_understanding_similarity_list.append([sentence_similarity, marked_understanding])\n",
    "                if debug:print(sentence_understanding_similarity_list)\n",
    "                \n",
    "                #normalize similarity\n",
    "                for similarity_ind in range(len(sentence_understanding_similarity_list)):\n",
    "                    sentence_understanding_similarity_list[similarity_ind][0] /=sum_similarity\n",
    "                if debug:print(sentence_understanding_similarity_list)\n",
    "                \n",
    "                #math probability of sentence understanding\n",
    "                math_prob = 0\n",
    "                for similarity_ind in range(len(sentence_understanding_similarity_list)):\n",
    "                    m_e = float(sentence_understanding_similarity_list[similarity_ind][0])\n",
    "                    mark = float(sentence_understanding_similarity_list[similarity_ind][1])\n",
    "                    math_prob +=  m_e* mark\n",
    "                    if debug: print(sentence_understanding_similarity_list[similarity_ind][0], sentence_understanding_similarity_list[similarity_ind][1], m_e* mark)\n",
    "                if debug: print(\"final\",math_prob)\n",
    "                whole_text_sent_understanding_prob_list.append(math_prob)\n",
    "        if (whole_text_sent_understanding_prob_list):\n",
    "            final_sent_understanding_prediction = statistics.mean(whole_text_sent_understanding_prob_list)\n",
    "            return final_sent_understanding_prediction\n",
    "        else:\n",
    "            return 0\n",
    "            \n",
    "sentence_recommendation_from_marked_dataset(\"./sentence_features_json/text_0.json\", sentence_db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.6503</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.007800</td>\n",
       "      <td>0.007800</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.093184</td>\n",
       "      <td>0.237405</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.5626</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>0.014890</td>\n",
       "      <td>0.011259</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.169718</td>\n",
       "      <td>0.201980</td>\n",
       "      <td>0.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.4951</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.028309</td>\n",
       "      <td>0.012447</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.170251</td>\n",
       "      <td>0.190485</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.6321</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.013009</td>\n",
       "      <td>0.018568</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.223918</td>\n",
       "      <td>0.214968</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.6601</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>0.028585</td>\n",
       "      <td>0.004112</td>\n",
       "      <td>0.004621</td>\n",
       "      <td>0.106511</td>\n",
       "      <td>0.206026</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        0     1         2         3         4         5         6         7  \\\n",
       "0  0.6503  0.65  0.200000  0.200000  0.007800  0.007800  0.000000  0.093184   \n",
       "1  0.5626  0.72  0.153846  0.307692  0.014890  0.011259  0.000000  0.169718   \n",
       "2  0.4951  0.83  0.166667  0.000000  0.028309  0.012447  0.000000  0.170251   \n",
       "3  0.6321  0.66  0.000000  0.250000  0.013009  0.018568  0.000000  0.223918   \n",
       "4  0.6601  0.62  0.142857  0.214286  0.028585  0.004112  0.004621  0.106511   \n",
       "\n",
       "          8     9  \n",
       "0  0.237405  0.50  \n",
       "1  0.201980  0.40  \n",
       "2  0.190485  0.50  \n",
       "3  0.214968  0.25  \n",
       "4  0.206026  0.50  "
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_db = pd.read_csv(\"text_db.csv\", header = None)\n",
    "text_db.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5499385780058443"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def text_recommendation_from_marked_dataset(recommended_text_precalculated_text_feat_similarity, text_feat_competence_db, debug = False):\n",
    "    with open(recommended_text_precalculated_text_feat_similarity, \"r\", encoding = \"utf-8\") as f:\n",
    "        text_similarity_dict = json.load(f)\n",
    "        if text_similarity_dict:\n",
    "            sum_similarity = 0\n",
    "            text_understanding_similarity_list = []\n",
    "            for rec_text_element in text_similarity_dict:\n",
    "                rec_text_index = rec_text_element[0]\n",
    "                marked_understanding = list(text_feat_competence_db.iloc[rec_text_index])[-1]\n",
    "                text_similarity = rec_text_element[1]\n",
    "                sum_similarity += text_similarity\n",
    "                text_understanding_similarity_list.append([text_similarity, marked_understanding])\n",
    "            if debug:print(text_understanding_similarity_list)\n",
    "                \n",
    "            #normalize similarity\n",
    "            for similarity_ind in range(len(text_understanding_similarity_list)):\n",
    "                text_understanding_similarity_list[similarity_ind][0] /=sum_similarity\n",
    "            if debug:print(text_understanding_similarity_list)\n",
    "                \n",
    "            #math probability of sentence understanding\n",
    "            math_prob = 0\n",
    "            for similarity_ind in range(len(text_understanding_similarity_list)):\n",
    "                m_e = float(text_understanding_similarity_list[similarity_ind][0])\n",
    "                mark = float(text_understanding_similarity_list[similarity_ind][1])\n",
    "                math_prob +=  m_e* mark\n",
    "                if debug: print(text_understanding_similarity_list[similarity_ind][0], text_understanding_similarity_list[similarity_ind][1], m_e* mark)\n",
    "            if debug: print(\"final\",math_prob)\n",
    "            return math_prob\n",
    "        else:\n",
    "            return 0\n",
    "text_recommendation_from_marked_dataset(\"./texts_features_json/text_0.json\", text_db, debug = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer_dict = {\"222\" :['0-' ,'1-' ,'2+' ,'4+'],\n",
    "\"862\":['1+','2-', '4+', '6-', '12-'],\n",
    "\"321\":['5+' ,'0-' ,'4-' ,'1+'],\n",
    "\"364\":['2+', '6-', '3-', '7-' ],\n",
    "\"502\":['13-', '3+', '0-', '4+'],\n",
    "\"878\":['3-', '0+', '4-', '1-'],\n",
    "\"666\":['3-', '1-', '2-' ],\n",
    "\"92\":['1+', '2-'],\n",
    "\"615\":['1+', '2-'],\n",
    "\"450\":['6-', '7-', '11+', '9+' ,'10+' ],\n",
    "\"722\":['1+', '6-', '2+', '3+', '6-', '8-'],\n",
    "\"732\":['8-', '0-', '3-', '4-', '2+', '1-'],\n",
    "\"611\":['1+'],\n",
    "\"251\":['5-', '4+', '2+', '1+', '3+']}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "a =2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.24949928655405482"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def calc_dev_from_eighty_percent(understanding_vector):\n",
    "    diff_squared = 0\n",
    "    for value in understanding_vector:\n",
    "        diff_squared += (value - 0.8) ** 2\n",
    "        #print(value - 0.8, (value - 0.8) ** 2,diff_squared )\n",
    "    diff_squared /= 3\n",
    "    #print(diff_squared)\n",
    "    st_dev = math.sqrt(diff_squared)\n",
    "    return st_dev\n",
    "calc_dev_from_eighty_percent(text_recommendation_vector_dict[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 898/898 [02:51<00:00,  5.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2min 51s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "text_recommendation_vector_dict = {}\n",
    "text_recommendation_dict = {}\n",
    "for text_ind in tqdm(range(len(db_3000))):\n",
    "    if str(text_ind) not in list(answer_dict.keys()):\n",
    "        trigramms_path = \"./words_features_json/text_\" + str(text_ind) + \".json\"\n",
    "        sent_path = \"./sentence_features_json/text_\" + str(text_ind) + \".json\"\n",
    "        text_path = \"./texts_features_json/text_\" + str(text_ind) + \".json\"\n",
    "        trigr_recommendation = trigramm_recommendation_from_marked_dataset(trigramms_path, trigramms_db)\n",
    "        sentence_recommendation = sentence_recommendation_from_marked_dataset(sent_path, sentence_db)\n",
    "        text_recommendation = text_recommendation_from_marked_dataset(text_path, text_db)\n",
    "        text_standard_deviation = calc_dev_from_eighty_percent([trigr_recommendation, sentence_recommendation, text_recommendation])\n",
    "        text_recommendation_vector_dict[text_ind] = [trigr_recommendation, sentence_recommendation, text_recommendation]\n",
    "        text_recommendation_dict[text_ind] = text_standard_deviation\n",
    "sorted_text_feat_dict = sorted(text_recommendation_dict.items(), key=operator.itemgetter(1), reverse = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(693, 0.1590651833868331),\n",
       " (279, 0.18096641885266368),\n",
       " (748, 0.1813461748178669),\n",
       " (194, 0.187156821930423),\n",
       " (629, 0.18936899042194447)]"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_text_feat_dict = sorted(text_recommendation_dict.items(), key=operator.itemgetter(1), reverse = False)\n",
    "sorted_text_feat_dict[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ИЗВЛЕКАЕМ ТЕКСТЫ ДЛЯ ВОПРОС"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ud_class import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model('./udpipe parsers/russian-syntagrus-ud-2.0-170801.udpipe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_conllu_from_unite_line_text(text, model):\n",
    "    sentences = model.tokenize(text)\n",
    "    for s in sentences:\n",
    "        model.tag(s)\n",
    "        model.parse(s)\n",
    "    conllu = model.write(sentences, \"conllu\")\n",
    "    return conllu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_conllu_text_map(conllu_parsed_object):\n",
    "    conllu_text_map = []\n",
    "    conllu_sentence_map = []\n",
    "    for line in conllu_parsed_object.split('\\n'):\n",
    "        if line:\n",
    "            if line[0].isdigit():\n",
    "                #print(line.split('\\t'))\n",
    "                conllu_sentence_map.append(line.split('\\t'))\n",
    "            else:\n",
    "                if(len(conllu_sentence_map) > 0):\n",
    "                    conllu_text_map.append(conllu_sentence_map)\n",
    "                    conllu_sentence_map = []   \n",
    "                    #print(\"appended\")\n",
    "    if(len(conllu_sentence_map) > 0):\n",
    "        conllu_text_map.append(conllu_sentence_map)\n",
    "    return conllu_text_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lemm_and_orig_text_from_udmap(conllu_map):\n",
    "    lemm_sentences_list = []\n",
    "    sentences_list = []\n",
    "    for sentence in conllu_map:\n",
    "        lemm_line = ''\n",
    "        line = ''\n",
    "        for word in sentence: \n",
    "            if (word[3] != 'PUNCT'):\n",
    "                #print(word[2])\n",
    "                lemm_line += word[2] + ' '\n",
    "                line += word[1] + ' '\n",
    "        \n",
    "        lemm_sentences_list.append(lemm_line.strip())\n",
    "        sentences_list.append(line.strip())\n",
    "        #print()\n",
    "    return lemm_sentences_list, sentences_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['В пятницу представители Северной Кореи признали что их ВМФ также понес потери в результате столкновения с военными кораблями Южной Кореи сообщает AP',\n",
       " 'Неожиданная перестрелка между кораблями Северной и Южной Корей произошедшая 29 июня в результате безрассудной вооруженной провокации со стороны судов Южной Кореи привела к человеческим потерям с обеих сторон и потере одного военного корабля говорится в заявлении Центрального новостного агентства Северной Кореи',\n",
       " 'Это первое признание Северной Кореей своих потерь однако величину их она предпочла оставить в секрете',\n",
       " 'Ранее представители Южной Кореи сообщили что в ходе столкновения потеряли четырех своих моряков',\n",
       " 'По их подсчетам потери Северной Кореи должны были составить не менее 30 человек']"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conllu = get_conllu_from_unite_line_text(db_3000.iloc[int(222)]['texts_3000'], model)\n",
    "conllu_text_map = get_conllu_text_map(conllu)\n",
    "lemm_sentences,sentences_list = get_lemm_and_orig_text_from_udmap(conllu_text_map)\n",
    "sentences_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['В пятницу представители Северной Кореи признали что их ВМФ также понес потери в результате столкновения с военными кораблями Южной Кореи сообщает AP', 'Неожиданная перестрелка между кораблями Северной и Южной Корей произошедшая 29 июня в результате безрассудной вооруженной провокации со стороны судов Южной Кореи привела к человеческим потерям с обеих сторон и потере одного военного корабля говорится в заявлении Центрального новостного агентства Северной Кореи', 'Это первое признание Северной Кореей своих потерь однако величину их она предпочла оставить в секрете', 'Ранее представители Южной Кореи сообщили что в ходе столкновения потеряли четырех своих моряков', 'По их подсчетам потери Северной Кореи должны были составить не менее 30 человек']\n",
      "['Марсоход НАСА Curiosity обнаружил новые доказательства существования озера на Красной планете', 'Об этом ТАСС сообщили представители американской Лаборатории реактивного движения ЛРД в Пасадене штат Калифорния', 'Собранные результаты исследований породы горы Шарп по данным ЛРД позволяют говорить о том что на поверхности Марса существовали обширные озера', 'Кроме того ученые полагают что атмосфера Марса могла поддерживать температуру выше нуля градусов', 'Ученые обнаружили что порода не однообразна а состоит из различных слоев причем некоторые из них были образованы под воздействием воды и ветра в течение миллионов лет', 'Ученые предполагают что 3,8 миллиарда лет назад горы Шарп на Марсе не было а на ее месте находилось крупное озеро или цепь водоемов', '«Чем выше поднимется Curiosity тем больше экспериментов мы сможем поставить и понять какие изменения происходили в этих озерах', 'Возможно новые опыты подарят надежду найти следы существования форм жизни на Марсе» считают в ЛРД', 'Космический аппарат уже несколько раз использовал буровую установку для получения проб почвы', 'Образцы полученной с этого места породы также содержали доказательства существования воды на Красной планете', 'Curiosity «Кьюриосити» прибыл на Марс 6 августа 2012 года для исследования кратера Гейла', 'Аппарат способен преодолевать препятствия высотой до 75 сантиметров и делать полный разворот на месте', 'Этот проект обошелся НАСА в 2,5 миллиарда долларов']\n",
      "['В Москве на улице Петровка в одном из домов в четверг вечером начался крупный пожар сообщает РИА Новости', 'По данным представителя УГПС горит крыша дома номер 17 корпус четыре', 'Общая площадь пожара превышает 150 квадратных метров', 'К месту происшествия было вызвано десять пожарных расчетов и две бригады скорой помощи а также представители патрульно постовой службы ГИБДД', 'Данных о пострадавших пока не поступало', 'По сообщению пожарных в настоящее время решается вопрос о перекрытии движения по улице Петровка']\n",
      "['Согласно данным министерства торговли США объем розничных продаж в июне вырос на 1,1 процента до 299,53 миллиарда долларов сообщает Reuters', 'Эксперты ожидали роста розничных продаж в июне на 0,7 процента', 'Основным фактором роста этого показателя стало увеличение продаж автомобилей и одежды', 'Министерством торговли также была пересмотрена цифра снижения розничных продаж в мае', 'Если ранее заявлялось о 0,9 процентах падения продаж то сейчас эта цифра составлет 1,1 процента', 'Данные свидетельствующие о том что фактор потребительского спроса продолжал оказывать свое благоприятное воздействие на экономику сегодня дополнились негативной информацией от Мичиганского университета о резком падении потребительского доверия в июле', 'Предварительный показатель потребительского доверия в США за текущий месяц снизился с 92,4 до 86,5 что является самым низким показателем за восемь последних месяцев', 'Наблюдатели отмечают что падение потребительского доверия может быть вызвано падением курса акций на фондовом рынке и сложной ситуацией на рынке труда']\n",
      "['Президенты России и Белоруссии Владимир Путин и Александр Лукашенко считают что некоторые вопросы в строительстве союзного государства перезрели и надеются что начавшийся в пятницу Высший Госсовет Союза РФ и Белоруссии поможет серьезно продвинуться в их решении', 'С таким заявлением главы двух государств выступили на встрече в Кремле сообщает РИА Новости', 'Президент РФ рассчитывает что заседание пройдет как обычно в деловом ключе очень конструктивно', 'Тем более что по этому поводу мы давно не собирались уточнил он', 'Путин предложил белорусскому коллеге обсудить вопросы по бюджету Союзного государства а также некоторые другие проблемы по тематике строительства Союзного государства России и Белоруссии', 'В свою очередь Лукашенко отметил подвижки в отношениях двух стран которые произошли после встречи российского и белорусского лидеров в Сочи начале апреля', 'Уже есть очень хорошая положительная реакция со стороны наших людей россиян и белорусов сказал президент Белоруссии', 'Они все-таки надеются что нам удастся продвинуться по направлению строительства Союзного государства', 'Ранее Лукашенко сообщил что первыми в повестке дня переговоров стоят вопросы о единой валюте Конституционном акте бюджете и ряд других вопросов', 'Бюджет это главное', 'Вчера парламентарии его приняли', 'Сейчас он подлежит утверждению на Высшем Госсовете сказал президент', 'К важным вопросам Лукашенко отнес и вопросы унификации законодательства', 'И даже не унификация а предоставление на практике равных прав белорусам в России россиянам в Белоруссии уточнил президент пояснив что речь идет о здравоохранении пенсионном обеспечении образовании']\n",
      "['Виктор Янукович обнародовал данные о ценных бумагах которыми он владеет', 'Как сообщает Украинская правда со ссылкой на пресс-службу президента Украины их общая стоимость составляет 6567 гривен примерно 25,3 тысячи рублей', \"По данным газеты Януковичу принадлежит в частности 10160 акций ОАО Донецкавтотранс которые он приобрел в 1996 году 100 акций ОАО Украинская страховая компания Авто' с 1994 года 3027 акций Проминвестбанка с 1995 года\", 'В пресс-службе президента сообщили что с момента приобретения прав собственности на указанные акции никаких операций с ними не осуществлялось а также отметили что в 2006 году в соответствии с требованиями закона О выборах народных депутатов Украины принадлежащие Виктору Януковичу корпоративные права были переданы в управление другому лицу', 'В октябре 2010 года Украинская правда подала в суд на Януковича требуя рассказать долями в каких предприятиях он владеет', 'Это произошло после того как президент указал в своей декларации о доходах что ему принадлежит несколько пакетов акции общей стоимостью 6,5 тысяч гривен', 'Пытаясь выяснить о каких конкретно акциях идет речь журналисты Украинской правды дважды посылали соответствующие запросы один в президентскую администрацию второй непосредственно Януковичу', 'Не получив ответа газета обратилась в Высший административный суд Украины с иском против президента указав что он скрывая информацию о своем имуществе нарушает ряд законов', 'Будет ли иск отозван теперь Украинская правда не сообщает']\n",
      "['В ходе устроенной Министерством финансов США проверки налоговых инспекций страны выяснилось что почти в половине случаев их работники предоставляют налогоплательщикам неверную информацию сообщает газета Washington Post', 'Проверяющие министерства финансов под видом простых граждан посетили 47 центров помощи налогоплательщикам чьи работники на 49 процентов вопросов дали неверные ответы', 'Также проверяющие воспользовались горячей телефонной линией налоговой инспекции сумев дозвониться лишь в двух третях случаев', 'Задавая по телефону вопросы которые входят в список наиболее часто задаваемых они смогли получить правильные ответы лишь на 47 процентов из них', 'Проблема низкого профессионального уровня предоставления помощи налогоплательщикам преследует налоговую инспекцию США на протяжение многих лет', 'Существует много историй о налогоплательщиках которые следуя полученным рекомендациям налоговой инспекции позднее вынуждены были платить штрафы']\n",
      "['Military.com', 'Дело в том что в конце февраля Пентагон объявил о том что собирается ликвидировать часть военных баз на территории США', 'Точное число баз которые подлежат закрытию а также названия хотя бы некоторых из них неизвестны']\n",
      "['Руководство Министерства обороны Российской Федерации в очередной раз распорядилось ограничить доступ журналистов к информации о происходящем в Чечне', 'Об этом сообщает Агентство военных новостей со ссылкой на источник в Минобороны РФ', 'По его сведениям это объясняется участившимися в последнее время обвинениями со стороны правительственных и политических кругов в адрес высшего военного руководства неоправданно затянувшего военную операцию в Чечне', 'В то же время источник не исключил что главная цель этого распоряжения скрыть ожидаемые большие потери федеральных войск в ходе боевых действий в сильно укрепленных горных районах Чечни']\n",
      "['Правительство России не планирует национализировать полезные ископаемые и не рассматривает никаких законопроектов по данному вопросу', 'Об этом заявил заместитель руководителя аппарата правительства Алексей Волин передает агентство РИА Новости', 'Ранее газета Ведомости сообщила что администрация президента направила в правительство законопроект по которому полезные ископаемые добываемые сырьевыми компаниями предлагается сделать собственностью государства действующие лицензии на месторождения отменить а вместо них заключить с компаниями договоры подряда и концессии', 'Как сообщил Волин правительство не получало от администрации президента никаких документов по этому вопросу', 'По его словам в любом случае такие документы должны пройти предварительную экспертизу в профильных министерствах и ведомствах', 'Волин заявил что кабинет министров исходит из необходимости сохранения действующих условий работы компаний занимающихся добычей полезных ископаемых', 'По его мнению обсуждаемые в средствах массовой информации различные законопроекты касающиеся вопросов регулирования недропользования в любом случае никак не могут относиться к уже действующим проектам и соглашениям', 'Как заявил Волин при любых раскладах условия работы действующих компаний не могут ухудшаться', 'По словам Волина все последние годы правительство демонстрировало что любые изменения правил игры на рынке происходят только в лучшую для его участников сторону', 'Это касается как представителей российских деловых кругов так и зарубежных инвесторов', 'Газета Ведомости писала что законопроект о передаче добываемых полезных ископаемых в собственность государству планируется представить в Госдуму уже к первому ноября', 'До этого времени он должен быть доработан администрацией президента и правительством', 'Газета писала что об этом сообщил заместитель руководителя администрации президента Дмитрий Козак', 'Комментируя законопроект руководители некоторых российских сырьевых компаний заявили Ведомостям что речь идет о национализации отрасли', 'Инвесторы заявили что в случае реализации предложений администрации начнется массовое бегство капитала из России а курс акций российских сырьевых компаний пойдет вниз']\n",
      "['Компания Coca-Cola займется производством молока под премиальным брендом Fairlife', 'Стоимость продукции выпущенной под этой маркой будет в два раза выше по сравнению со стандартным молоком в американских магазинах', 'Как пишет The Daily Telegraph продажи продукта в США начнутся в декабре 2014 года', 'Потребителям будет предложен продукт с высоким содержанием белка пониженным содержанием сахара и без лактозы', 'Старший вице-президент Coca-Cola Сэнди Дуглас Sandy Douglas рассказал что молоко Fairlife будет содержать на 50 процентов больше белка чем обычное и на 30 процентов меньше сахара а также «будет вкуснее»', 'Представитель производителя считает что бренд имеет «потрясающий потенциал роста» и со временем Fairlife начнет приносить значительный доход', '«В течение какого-то времени мы собираемся инвестировать в молочный бизнес на создание бренда поэтому в первые пару лет деньги не потекут', 'Но если вы все делаете хорошо то деньги потекут позже» сказал Дуглас', 'The Daily Telegraph отмечает что Coca-Cola выходит на молочный рынок в сложное время когда продажи традиционного молока в США падают а прибыль от ароматизированного молока и молока с высоким содержанием белка растет']\n",
      "['Северная и Южная Корея не могут согласовать совместное заявление по итогам двусторонних переговоров первых за последние 10 месяцев сообщает Bloomberg.com', 'Очередная встреча представителей двух сторон состоялась в среду в Северной Корее и продолжалось лишь около 15 минут', 'Согласно делегации Южной Кореи было достигнуто соглашение о продолжении переговоров в четверг', 'Мы четко дали понять что не можем согласиться наличием у Северной Кореи ядерного оружия и что сотрудничество невозможно если Северная Корея не сможет придерживаться тех принципов что ядерного оружия на Корейском полуострове быть не должно заявил заместитель министра Южной Кореи по вопросам объединения Ли Бон Чжо', 'Мы подчеркнули что Северная Корея должна вернуться к шестисторонним переговорам для обеспечения взаимной безопасности и процветания нашего народа', 'Между тем представители Северной Кореи отказываются включить в совместное заявление по итогам встречи пункт о своей приверженности продолжению шестисторонних переговоров по нормализации обстановки на Корейском полуострове', 'Он также сообщил что стороны в принципе договорились провести переговоры на уровне министров но так и не смогли согласовать дату их проведения', 'Именно этот вопрос станет темой завтрашней встречи', 'Напомним что ранее Ли сообщил что Южная Корея готова выступить с новой инициативой если Пхеньян согласится возобновить шестисторонние переговоры по своей ядерной программе не уточнив впрочем о какой именно инициативе идет речь']\n",
      "['Вести.ру', 'Время новостей оба самолета пилотировали летчики в звании полковника']\n",
      "['Владивосток официально стал административным центром Приморского края', 'Такое решение было принято на заседании Законодательного собрания 30 марта', 'Как сообщает информационное агентство Дейта.Ru с просьбой поддержать законопроект обратился к депутатам глава города Владимир Николаев', 'В результате закон О статусе города Владивостока административного центра Приморского края был принят принят сразу во втором и третьем чтениях', 'До этого момента вопрос о статусе города обсуждался в течение шести лет', 'Отныне город сможет получать из краевого бюджета не менее 300 миллионов рублей в качестве компенсации расходов на выполнение столичных функций как -то проведение краевых и федеральных мероприятий охрану памятников содержание строительство дорог и так далее', 'Ранее все это город оплачивал из муниципального бюджета']\n"
     ]
    }
   ],
   "source": [
    "for text_ind in list(answer_dict.keys()):\n",
    "    text = db_3000.iloc[int(text_ind)]['texts_3000']\n",
    "    conllu = get_conllu_from_unite_line_text(text, model)\n",
    "    conllu_text_map = get_conllu_text_map(conllu)\n",
    "    lemm_sentences,sentences_list = get_lemm_and_orig_text_from_udmap(conllu_text_map)\n",
    "    print(sentences_list)\n",
    "    text_path = \"./texts_for_questions/text_\" + text_ind + \".txt\"\n",
    "    with open(text_path, \"w\", encoding = \"utf-8\") as f:\n",
    "        for sentence_ind in range(len(sentences_list)):\n",
    "            f.write(str(sentence_ind) + ' ' + sentences_list[sentence_ind] + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_features_precalculation_initial (rec_text_map, marked_text_db):\n",
    "    rec_text_text_similarity_dict = {}\n",
    "    rec_text_features = []\n",
    "    rec_text_features.append(rec_text_map['lix'])\n",
    "    rec_text_features.append(rec_text_map['ttr'])\n",
    "    rec_text_features.extend(rec_text_map['sent_properties'])\n",
    "    rec_text_vec = np.array(rec_text_features).reshape(1, -1)\n",
    "    #print(rec_text_vec)\n",
    "    text_similarity_dict = {}\n",
    "    for text_similarity_ind in range(len(marked_text_db)):\n",
    "        text_vec = marked_text_db.iloc[text_similarity_ind][:-1].values.reshape(1, -1)\n",
    "        #print(text_vec)\n",
    "        similarity = cosine_similarity(rec_text_vec,text_vec)\n",
    "        #print(similarity)\n",
    "        text_similarity_dict[text_similarity_ind] = similarity[0][0]\n",
    "    sorted_text_feat_dict = sorted(text_similarity_dict.items(), key=operator.itemgetter(1), reverse = True)\n",
    "    text_feeat_mean_dict = []\n",
    "    return sorted_text_feat_dict[:min(5, len(sorted_text_feat_dict))]\n",
    "text_features_precalculation(potential_recommended_text_map, text_db)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sent_features_recommendation_initial (rec_text_map, marked_sentences_db):\n",
    "    sentences_understanding = {}\n",
    "    sentence_map = rec_text_map['sentences_map']\n",
    "    for sentence_ind in range(len(sentence_map)):\n",
    "        rec_sent_feat = []\n",
    "        rec_sent_feat.append(sentence_map[sentence_ind]['spec_sentence_features']['negation'])\n",
    "        rec_sent_feat.append(sentence_map[sentence_ind]['spec_sentence_features']['coreference'])\n",
    "        rec_sent_feat.append(sentence_map[sentence_ind]['spec_sentence_features']['vozvr_verb'])\n",
    "        rec_sent_feat.append(sentence_map[sentence_ind]['spec_sentence_features']['prich'])\n",
    "        rec_sent_feat.append(sentence_map[sentence_ind]['spec_sentence_features']['deepr'])\n",
    "        rec_sent_feat.append(sentence_map[sentence_ind]['spec_sentence_features']['case_complexity'])\n",
    "        rec_sent_feat.append(sentence_map[sentence_ind]['spec_sentence_features']['mean_depend_length'])\n",
    "        rec_sent_vec = np.array(rec_sent_feat).reshape(1, -1)\n",
    "        sent_similarity_dict = {}\n",
    "        for sent_ind in range(len(marked_sentences_db)):\n",
    "            sent_vec = marked_sentences_db.iloc[sent_ind][:-1].values.reshape(1, -1)\n",
    "            similarity = cosine_similarity(rec_sent_vec,sent_vec)\n",
    "            #print(similarity)\n",
    "            sent_similarity_dict[sent_ind] = similarity[0][0]\n",
    "        sorted_sent_similarity_dict = sorted(sent_similarity_dict.items(), key=operator.itemgetter(1), reverse = True)\n",
    "        filtered = filter_similar(sorted_sent_similarity_dict)\n",
    "        \n",
    "        \"\"\"\n",
    "        sent_similarity_list = []\n",
    "        for sim_sent in sorted_sent_similarity_dict[:3]:\n",
    "            print(sim_sent)\n",
    "            sent_undestanding_mark = list(marked_sentences_db.iloc[sim_sent[0]])[-1]\n",
    "            sent_similarity_list.append(sent_undestanding_mark)\n",
    "        \"\"\"\n",
    "        sentences_understanding[sentence_ind] = filtered\n",
    "    return sentences_understanding\n",
    "sent_features_recommendation(potential_recommended_text_map, sent_dp)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trigramms_recommendation_intial (rec_text_map, marked_trigramms_db, trigrmms_list):\n",
    "    sentences_map = rec_text_map['sentences_map']\n",
    "    calc_text_dict = {}\n",
    "    for sentence_ind in tqdm(range(len(sentences_map))):\n",
    "        for word in sentences_map[sentence_ind]['sentence_words']:\n",
    "            text_word_vec = word['lex_vector'].reshape(1, -1)\n",
    "            text_word_dist_dict = {}\n",
    "            for word_db_ind in range(len(marked_trigramms_db)):\n",
    "                marked_trigramms_db_word_vec = marked_trigramms_db.iloc[word_db_ind][:-1].values.reshape(1, -1)\n",
    "                similarity = cosine_similarity(text_word_vec,marked_trigramms_db_word_vec)\n",
    "                text_word_dist_dict[word_db_ind] = similarity\n",
    "           \n",
    "            sorted_x = sorted(text_word_dist_dict.items(), key=operator.itemgetter(1), reverse = True)\n",
    "            filtered_sorted_list = filter_similar_trigramms(sorted_x)\n",
    "            if not filtered_sorted_list:\n",
    "                calc_text_dict[word['lex_trigram']] = None\n",
    "            else:\n",
    "                similar_trigrams= []\n",
    "                for similar_el in filtered_sorted_list:\n",
    "                    similar_trigrams.append((similar_el, trigrmms_list[similar_el[0]],list(marked_trigramms_db.iloc[similar_el[0]])[-1] ))\n",
    "                calc_text_dict[word['lex_trigram']] = similar_trigrams\n",
    "                #=====ЗДЕСЬ ПР ПОДГРУЗКЕ НАДО БУДЕТ РАЗМЕТИТЬ ЦЕЛЕВУЮ ПЕРЕМЕННУЮВ СООТВТЕТСВИИ С КОРРЕКТНОСТЬЮ ОТВЕТА И ДАЛЕЕ ПЛЯСАТЬ\n",
    "                \n",
    "    vocab_recommendation_dict = {}\n",
    "    for key in calc_text_dict.keys():\n",
    "        print(key , \"===>\", calc_text_dict[key],'\\n')\n",
    "        understdanding_prob_list = []\n",
    "        if (calc_text_dict[key]):\n",
    "            for trgrm in calc_text_dict[key]:\n",
    "                understdanding_prob = trgrm[2]\n",
    "                understdanding_prob_list.append(understdanding_prob)\n",
    "            understdanding_prob_mean = statistics.mean(understdanding_prob_list) \n",
    "            vocab_recommendation_dict[key] = understdanding_prob\n",
    "    positive_understanding_prob = 0\n",
    "    whole_understading_prob = 0 \n",
    "    for key in vocab_recommendation_dict.keys():\n",
    "        print(key , \"===>\", vocab_recommendation_dict[key],'\\n')\n",
    "        if (vocab_recommendation_dict[key] > 0):\n",
    "            positive_understanding_prob += vocab_recommendation_dict[key]\n",
    "            whole_understading_prob += abs(vocab_recommendation_dict[key])\n",
    "        elif(vocab_recommendation_dict[key] < 0):\n",
    "            whole_understading_prob += abs(vocab_recommendation_dict[key])\n",
    "    understanding_prob = positive_understanding_prob/whole_understading_prob\n",
    "    print(\"understanding_prob\",understanding_prob)\n",
    "        \n",
    "trigramms_recommendation(potential_recommended_text_map,word_dp,  trigramms)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
