{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.keyedvectors import FastTextKeyedVectors\n",
    "fasttext = FastTextKeyedVectors.load(\"D:/fasttext_word2vec/araneum_none_fasttextcbow_300_5_2018/araneum_none_fasttextcbow_300_5_2018.model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Asus\\Anaconda3\\lib\\site-packages\\gensim\\utils.py:1212: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "from text_processing import get_text_map\n",
    "from os import listdir\n",
    "from os.path import join\n",
    "import random\n",
    "import json\n",
    "from collections import OrderedDict\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open (\"./colloc/music_unigr_freq.json\", 'r', encoding = 'utf-8') as f:\n",
    "    unigr_freq = json.load(f)\n",
    "    \n",
    "with open (\"./colloc/music_smart_colloc_freq_test.json\", 'r', encoding = 'utf-8') as f:\n",
    "    colloc_freq = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts_lenta = pd.read_csv(\"./articles/music_lenta.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts_index = [0,\n",
    "17,\n",
    "26,\n",
    "32,\n",
    "98,\n",
    "121,\n",
    "130,133,\n",
    "200,\n",
    "231,240,316,331,334,336,366,371]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(texts_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_maps_json_dict[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "text_maps_json_dict = {}\n",
    "for tex_ind in texts_index:\n",
    "    text_map = get_text_map(texts_lenta.iloc[tex_ind]['text'],unigramm_db_path ='./colloc/music_unigr_freq.json', \n",
    "                            colloc_db_path = \"D:\\input\\music_smart_colloc_freq.json\", raw_text_input=True)\n",
    "    text_maps_json_dict[tex_ind] = text_map\n",
    "    \n",
    "#\"/Users/nigula/Desktop/long_term_storage/colloc/music_smart_colloc_freq.json\"\n",
    "#\"D:\\input\\music_smart_colloc_freq.json\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_text_sent_collocind_dict = {\"0\":{'0':[9,11],'2':[26,35],'5':[13,27]},\n",
    "                                     \"17\":{'0':[7,18],'2':[8,19],'4':[2,16],'8':[7,25],'10':[14,24],'12':[9,24]},\n",
    "                                     \"26\":{'0':[6,19],'5':[5,11],'7':[0,6],'13':[13,27]},\n",
    "                                     \"32\":{'3':[9,20],'5':[5,17],'14':[6,17],'18':[3,19]},\n",
    "                                    \"98\":{'0':[11,16],'4':[3,6],'5':[1,12],'8':[7,12]},\n",
    "                                    \"121\":{'1':[2,7],'3':[5,19],'4':[0,15],'4':[0,15],'6':[13,17],'11':[0,5]},#'0':[11,16],\n",
    "                                    \"130\":{'0':[17,28],'1':[0,7],'4':[1,8],'5':[6,10],'8':[15,19],'9':[12,28],'16':[0,12]},#,'3':[2,9]\n",
    "                                    \"133\":{'2':[19,35],'6':[8,13],'8':[3,12],'9':[7,16],'18':[8,19],'20':[0,8],'20':[0,8],'40':[11,20],'49':[0,15]},\n",
    "                                     \"200\":{'0':[11,14],'2':[11,17],'4':[0,15],'10':[0,10],'12':[5,12]},\n",
    "                                      \"231\":{'2':[0,7],'4':[0,19],'7':[0,12],'12':[13,30]},\n",
    "                                    \"240\":{'1':[0,13],'11':[0,8],'15':[5,20]},\n",
    "                                     \"316\":{'0':[12,20],'5':[8,13],'7':[9,20],'11':[20,27]},\n",
    "                       \n",
    "                                     \"331\":{'2':[14,23],'4':[4,12],'10':[4,14]},\"334\":{'1':[4,10],'2':[0,3],'5':[4,12],'8':[1,9]},\n",
    "                                     \"336\":{'1':[0,10],'7':[0,9],'10':[1,7],'13':[3,5]},\"366\":{'0':[0,4],'1':[0,12],'5':[15,24],'8':[8,20],'10':[0,15],'11':[0,18],'15':[2,11]},\n",
    "                                     \"371\":{'0':[9,21],'2':[13,20],'3':[11,25],'6':[2,7],'12':[0,16],'21':[0,30]}}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(question_text_sent_collocind_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "answers_dict = {}\n",
    "text_ind_keys = list(question_text_sent_collocind_dict.keys())\n",
    "text_ind_keys = [int(numb) for numb in text_ind_keys]\n",
    "text_ind_keys.sort()\n",
    "for key in text_ind_keys:\n",
    "    answers_dict[key] = OrderedDict()\n",
    "    key_list = list(question_text_sent_collocind_dict[str(key)].keys())\n",
    "    key_list = [int(numb) for numb in key_list]\n",
    "    print(\"orig\", key_list)\n",
    "    key_list.sort()\n",
    "    print(\"sorted\",key_list)\n",
    "    for setn_keys in key_list:\n",
    "        answers_dict[key][setn_keys] = True\n",
    "answers_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(list(ans_dict_enze.keys())), len(list(question_text_sent_collocind_dict.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts_lenta.iloc[371]['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tex_map = get_text_map(texts_lenta.iloc[371]['text'],unigramm_db_path = \"C:\\Autotutor\\improved_approach\\colloc\\music_unigr_freq.json\",\n",
    "                            colloc_db_path = \"D:\\input\\music_smart_colloc_freq.json\",raw_text_input=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tex_map['overall_colloc_text'][15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ans_dict_enze ={0: OrderedDict([(0, True), (2, True), (5, True)]),\n",
    " 17: OrderedDict([(0, True),\n",
    "              (2, False),\n",
    "              (4, True),\n",
    "              (8, True),\n",
    "              (10, True),\n",
    "              (12, True)]),\n",
    " 26: OrderedDict([(0, True), (5, True), (7, True), (13, True)]),\n",
    " 32: OrderedDict([(3, True), (5, True), (14, True), (18, False)]),\n",
    " 98: OrderedDict([(0, True), (4, False), (5, True), (8, True)]),\n",
    " 121: OrderedDict([#(0, True),вопрос проебан просто не вставлен в тест!!!!\n",
    "              (1, True),\n",
    "              (3, True),\n",
    "              (4, True),\n",
    "              (6, True),\n",
    "              (11, True)]),\n",
    " 130: OrderedDict([(0, True),\n",
    "              (1, True),\n",
    "             # (3, True),вопрос проебан просто не вставлен в тест!!!!\n",
    "              (4, True),\n",
    "              (5, False),\n",
    "              (8, True),\n",
    "              (9, True),\n",
    "              (16, True)]),\n",
    " 133: OrderedDict([(2, False),\n",
    "              (6, True),\n",
    "              (8, True),\n",
    "              (9, True),\n",
    "              (18, True),\n",
    "              (20, True),\n",
    "              (40, True),\n",
    "              (49, True)]),\n",
    " 200: OrderedDict([(0, True),(2, True), (4, True), (10, True), (12, True)]),\n",
    " 231: OrderedDict([(2, False), (4, False), (7, True), (12, True)]),\n",
    " 240: OrderedDict([(1, False), (11, True), (15, True)]),\n",
    " 316: OrderedDict([(0, True), (5, True), (7, True), (11, True)]),\n",
    " 331: OrderedDict([(2, False), (4, True), (10, True)]),\n",
    " 334: OrderedDict([(1, True), (2, True), (5, True), (8, True)]),\n",
    " 336: OrderedDict([(1, False), (7, True), (10, True), (13, True)]),\n",
    " 366: OrderedDict([(0, True),\n",
    "              (1, True),\n",
    "              (5, False),\n",
    "              (8, True),\n",
    "              (10, True),\n",
    "              (11, True),\n",
    "              (15, False)]),\n",
    " 371: OrderedDict([(0, True),\n",
    "              (2, True),\n",
    "              (3, True),\n",
    "              (6, True),\n",
    "              (12, True),\n",
    "              (21, True)])}#!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "effected_collocations_start_indexes_list = [i for i in range(effected_collocations_start_indexes_list[0],effected_collocations_start_indexes_list[1]+1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "class user_vector:\n",
    "    def __init__(self,debug = False):\n",
    "        self.debug = debug\n",
    "        self.vocab_features =[]\n",
    "        self.sentence_features =[]\n",
    "        #coreference_items, negation_items, sent_special_pos, dependencies_length, Y (answer)                   \n",
    "        self.text_fearues = [] #OrderedDict([(\"lix\",[]),(\"ttr\",[])])\n",
    "        self.answers_count = OrderedDict([(\"correct_answers\",0),(\"incorrect_answers\",0)])\n",
    "        self.collocations_list = []\n",
    "    def start_new_text(self):\n",
    "        self.answers_count['correct_answers'] = 0\n",
    "        self.answers_count['incorrect_answers'] = 0\n",
    "        if self.debug:print(\"answers count has been reset\", self.answers_count['correct_answers'], self.answers_count['incorrect_answers'])\n",
    "    \n",
    "    def end_text(self, text_map):\n",
    "        if self.debug:\n",
    "            print(\"\\n========\")\n",
    "            print(\"SUM UP TEXT VALUES\")\n",
    "            print(\"========\\n\")\n",
    "        correct_answers_rate = round(self.answers_count['correct_answers'] / (self.answers_count['correct_answers'] \n",
    "                                                                              + self.answers_count['incorrect_answers']),2)\n",
    "        current_text_features = []\n",
    "        if self.debug: \n",
    "            print(\"answers_count\", self.answers_count)\n",
    "        current_text_features.append(text_map['lix'])\n",
    "        current_text_features.append(text_map['ttr'])\n",
    "        current_text_features.append(text_map['sentences_count'])\n",
    "        current_text_features.append(text_map['average_sentence_length'])\n",
    "        #current_text_features.extend(text_map['vocab_properties'])\n",
    "        current_text_features.extend(text_map['sent_properties'])\n",
    "        current_text_features.append(correct_answers_rate)\n",
    "        self.text_fearues.append(current_text_features)\n",
    "        if self.debug: print(\"TEXT FEATURES\",self.text_fearues)\n",
    "    \n",
    "    def update_vector_with_answer_sentence(self, sentence_map, effected_collocations_start_indexes_list, correct_answer):\n",
    "        #update setnence and text features\n",
    "        if self.debug:\n",
    "            print(\"\\n===NEW REPLY CALCULATION====\")\n",
    "            print(\"\\n========\")\n",
    "            print(\"ADDING SENTENCE RESULTS\")\n",
    "            print(\"========\\n\")\n",
    "            \n",
    "        #update setnence and text features\n",
    "        if correct_answer == True:\n",
    "            answer_value = 1\n",
    "            self.answers_count['correct_answers'] += 1\n",
    "            if self.debug: print(\"Answer for this question is correct\")\n",
    "        else:\n",
    "            answer_value = 0\n",
    "            self.answers_count['incorrect_answers'] += 1\n",
    "            if self.debug: print(\"Answer for this question is incorrect\")\n",
    "        if self.debug:print(\"check answers count\", self.answers_count['correct_answers'], self.answers_count['incorrect_answers'])\n",
    "        current_sentence_features = []\n",
    "        current_sentence_features.append(sentence_map['spec_sentence_features']['negation'])\n",
    "        current_sentence_features.append(sentence_map['spec_sentence_features']['coreference'])\n",
    "        current_sentence_features.append(sentence_map['spec_sentence_features']['vozvr_verb'])\n",
    "        current_sentence_features.append(sentence_map['spec_sentence_features']['prich'])\n",
    "        current_sentence_features.append(sentence_map['spec_sentence_features']['deepr'])\n",
    "        current_sentence_features.append(sentence_map['spec_sentence_features']['case_complexity'])\n",
    "        current_sentence_features.append(sentence_map['spec_sentence_features']['mean_depend_length'])\n",
    "        \n",
    "        #current_sentence_features.extend(sentence_map['average_vocabulary'])\n",
    "        current_sentence_features.append(answer_value)#target variable\n",
    "        self.sentence_features.append(current_sentence_features)\n",
    "        \n",
    "        if self.debug: print(\"SENTENCE FEATURES\", current_sentence_features)\n",
    "        \n",
    "        if self.debug:\n",
    "            print(\"\\n========\")\n",
    "            print(\"ADDING VOCABULARY RESULTS\")\n",
    "            print(\"========\\n\") \n",
    "        effected_collocations_start_indexes_list_ranged = [i for i in range(effected_collocations_start_indexes_list[0],effected_collocations_start_indexes_list[1]+1)]    \n",
    "        for word_w in sentence_map['collocation_vectors_list']:\n",
    "            if word_w[0] in effected_collocations_start_indexes_list_ranged:\n",
    "                if self.debug:print(word_w[1][0])\n",
    "                current_word_features = []\n",
    "                #current_word_features.append(str(\"local_freq_\") + str(word_w[1][1]))\n",
    "                current_word_features.append(word_w[1][1])\n",
    "                #print(\"11\", word_w[1][1])\n",
    "                #current_word_features.append(str(\"global_freq_mpi_ln_\") + glob_freq_log)\n",
    "                current_word_features.append(word_w[1][2])\n",
    "                #print(\"12\",word_w[1][2])\n",
    "                current_word_features.extend(word_w[2][0])\n",
    "                #print(\"20\",word_w[2][0])\n",
    "                current_word_features.append(answer_value)\n",
    "                \n",
    "                self.collocations_list.append(word_w[1][0])\n",
    "                #print(current_word_features)\n",
    "                self.vocab_features.append(current_word_features)\n",
    "    def export_user_db(self, learner_id):\n",
    "                \n",
    "        words_db = np.array([np.array(word) for word in self.vocab_features])\n",
    "        word_db_path = learner_id + '_word_db.csv'\n",
    "        np.savetxt(word_db_path, words_db, delimiter=',') #, fmt='%s'\n",
    "        \n",
    "        sentence_db = np.array([np.array(sent) for sent in self.sentence_features])\n",
    "        sentence_db_path = learner_id + '_sentence_db.csv'\n",
    "        np.savetxt(sentence_db_path, sentence_db, delimiter=',') \n",
    "        \n",
    "        text_db = np.array([np.array(text) for text in self.text_fearues])\n",
    "        text_db_path = learner_id + '_text_db.csv'\n",
    "        np.savetxt(text_db_path, text_db, delimiter=',') \n",
    "        \n",
    "        with open(learner_id + \"_colloc_lit.txt\", \"w\", encoding = \"utf-8\") as f:\n",
    "            for line, line_vocab_feat in zip(self.collocations_list,self.vocab_features):\n",
    "                ans_val = line_vocab_feat[-1]\n",
    "                line_len = len(line.split())\n",
    "                if line in unigr_freq:\n",
    "                    freq_el = line + \"_\" + str(unigr_freq[line]) + \"_\" + str(ans_val)\n",
    "                    f.write(freq_el + '\\n')\n",
    "                elif line in colloc_freq[str(line_len)]:\n",
    "                    #print(line, \"found in colloc\")\n",
    "                    freq_el = line + \"_\" + str(colloc_freq[str(line_len)][line]) + \"_\" + str(ans_val)\n",
    "                    f.write(freq_el + '\\n')\n",
    "                else:\n",
    "                    print(line, \"not found\")\n",
    "                \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_maps_json_dict.keys(),len(list(text_maps_json_dict.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_text_sent_collocind_dict['0']['0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_maps_json_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text_index 0\n",
      "text_index 17\n",
      "text_index 26\n",
      "text_index 32\n",
      "text_index 98\n",
      "text_index 121\n",
      "text_index 130\n",
      "text_index 133\n",
      "text_index 200\n",
      "text_index 231\n",
      "text_index 240\n",
      "text_index 316\n",
      "text_index 331\n",
      "text_index 334\n",
      "text_index 336\n",
      "text_index 366\n",
      "text_index 371\n"
     ]
    }
   ],
   "source": [
    "DEBUG = False\n",
    "user = user_vector(debug = DEBUG)\n",
    "for text in text_maps_json_dict.keys():\n",
    "    print(\"text_index\", text)\n",
    "    text_map = text_maps_json_dict[text]\n",
    "    user.start_new_text()\n",
    "    for question_sentence_index in question_text_sent_collocind_dict[str(text)].keys():\n",
    "\n",
    "        user.update_vector_with_answer_sentence(text_map['sentences_map'][int(question_sentence_index)], \n",
    "                                        effected_collocations_start_indexes_list = question_text_sent_collocind_dict[str(text)][str(question_sentence_index)],\n",
    "                                        correct_answer = ans_dict_enze[int(text)][int(question_sentence_index)])\n",
    "\n",
    "        user.end_text(text_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "user.export_user_db(\"enze_big_musician\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
