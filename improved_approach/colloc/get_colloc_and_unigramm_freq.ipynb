{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from calculate_colocations import get_pos_filtered_colloc_from_corpus_list, get_colloc_from_corpus_list,get_clean_lemm_list\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Указом президента России Бориса Ельцина внесены изменения в  существующую структуру Федеральной службы безопасности РФ, утвержденную в июле прошлого года. Как говорится в поступившем сегодня сообщении Центра общественных связей ФСБ, в соответствии с Основами (Концепцией) государственной политики Российской Федерации по военномустроительству на период до 2005 года, на базе Департамента по борьбе с терроризмом и Управления конституционной безопасности ФСБ создан Департамент по защите конституционного строя и борьбе с терроризмом. В составе департамента организуются три управления с четко определенной компетенцией. В ФСБ отмечают, что \"в современных условиях для российскойгосударственности имеют приоритетное значение вопросы защитыконституционного строя, сохранения целостности страны, борьбыс терроризмом и всеми формами экстремизма, а также разведывательно-подрывной деятельностью спецслужб и организаций иностранных государств\". Как подчеркивается в сообщении, \"органам безопасности в решении данных проблем отведена особая роль\".'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts_lenta = pd.read_csv(\"3000.csv\")\n",
    "\n",
    "texts_lenta.iloc[0]['texts_3000']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 898/898 [02:18<00:00,  6.47it/s]\n"
     ]
    }
   ],
   "source": [
    "clean_lemm_list = get_clean_lemm_list(list(texts_lenta['texts_3000']),lang = 'rus')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'blue': 3, 'red': 2, 'yellow': 1})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "z = ['blue', 'red', 'blue', 'yellow', 'blue', 'red']\n",
    "Counter(z)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "unigramm_freq = Counter(clean_lemm_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'президент' in unigramm_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open (\"unigr_freq.json\",\"w\") as f:\n",
    "    json.dump(unigramm_freq, f, indent = 4, ensure_ascii = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "bigramFreqTable, trigramFreqTable, quadgram_freq, filtered_bi, filtered_tri, bigramPMITable, trigramPMITable, quadragramPMITable, bigramChiTable, trigramChiTable =get_pos_filtered_colloc_from_corpus_list(list(texts_lenta['texts_3000']),\"rus\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cean_pos_tags(df, ngramm_name):\n",
    "    clean_words = []\n",
    "    for i in tqdm(range(len(df))):\n",
    "        posed_ngramm = df.iloc[i][ngramm_name]\n",
    "        clean_ngramm = []\n",
    "        for w in posed_ngramm:\n",
    "            word = w.split(\"_\")[0]\n",
    "            clean_ngramm.append(word)\n",
    "        clean_ngramm = tuple(clean_ngramm)\n",
    "        clean_words.append(clean_ngramm)\n",
    "    \n",
    "    data = { \"ngramm\":clean_words,\"freq\":df['freq']}\n",
    "    clean_df = pd.DataFrame(data) \n",
    "    return clean_df\n",
    "bigramFreqTable_clean = cean_pos_tags(bigramFreqTable,'bigram')\n",
    "trigramFreqTable_clean = cean_pos_tags(trigramFreqTable, \"trigram\")\n",
    "quadgram_freq_clean = cean_pos_tags(quadgram_freq, \"quadgramF\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_tri.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_bi_clean = cean_pos_tags(filtered_bi,'bigram')\n",
    "filtered_tri_clean = cean_pos_tags(filtered_tri,'trigram')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_bi_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_freq_colloc_dict(ngrm_lis):\n",
    "    freq_colloc_dict = {'2':{},'3':{},'4':{}}\n",
    "    for ngramm_df in ngrm_lis:\n",
    "        dct = ngramm_df.to_dict(\"split\")\n",
    "        words_len = len(dct['data'][0][0])\n",
    "        for el in dct['data']:\n",
    "            \n",
    "            ngramm_raw = ''\n",
    "            for el_i in el[0]:\n",
    "                ngramm_raw += el_i + ' '\n",
    "            ngramm_raw = ngramm_raw.strip()\n",
    "            #print(ngramm_raw,words_len )\n",
    "            freq_colloc_dict[str(words_len)][ngramm_raw] = el[1]\n",
    "        \n",
    "    return freq_colloc_dict\n",
    "ngramms_list =[bigramFreqTable_clean, trigramFreqTable_clean, quadgram_freq_clean]\n",
    "freq_colloc_dict = get_freq_colloc_dict(ngramms_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_united_numeric_colloc_base (numeric_calc_collocations_list, collocations_by_freq_dict):#все кроме фильтрованных по частям речи\n",
    "    \n",
    "    overall_colloc_json = {'2':{},'3':{},'4':{}}\n",
    "    for colloc in numeric_calc_collocations_list:\n",
    "        colloc_len = len(colloc)\n",
    "        for key in list(colloc.keys()):\n",
    "            if 'gram' in key:\n",
    "                ngramm_name = key\n",
    "            else:\n",
    "                freq_name = key\n",
    "        n_of_words = str(len(colloc.iloc[0][ngramm_name]))\n",
    "        print(n_of_words)\n",
    "        for index in tqdm(range(int(colloc_len))):\n",
    "            collocation_element = colloc.iloc[index][ngramm_name]\n",
    "            str_el = ''\n",
    "            for el in collocation_element:\n",
    "                str_el += el + ' '\n",
    "            str_el = str_el.strip()\n",
    "            if str_el in collocations_by_freq_dict[n_of_words]:\n",
    "                overall_colloc_json[n_of_words][str_el] = collocations_by_freq_dict[n_of_words][str_el] \n",
    "            else:\n",
    "                overall_colloc_json[n_of_words][str_el] = colloc.iloc[index][freq_name]\n",
    "            \"\"\"\n",
    "            if str_el in overall_colloc_json[n_of_words]:\n",
    "                overall_colloc_json[n_of_words][str_el] *= int(colloc.iloc[index][freq_name])\n",
    "            else:\n",
    "                overall_colloc_json[n_of_words][str_el] = int(colloc.iloc[index][freq_name])\n",
    "            \"\"\"\n",
    "            #print(str_el)\n",
    "        #print(\"========\")\n",
    "    return overall_colloc_json\n",
    "#ngramms_list = [bigramFreqTable_clean, trigramFreqTable_clean, quadgram_freq_clean, bigramPMITable, trigramPMITable, quadragramPMITable]\n",
    "ngramms_list = [bigramPMITable, trigramPMITable, quadragramPMITable, bigramChiTable, trigramChiTable,filtered_bi_clean,filtered_tri_clean]\n",
    "\n",
    "log_collocations_vs_freq = get_united_numeric_colloc_base(ngramms_list,freq_colloc_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open (\"smart_colloc_freq.json\",\"w\") as f:\n",
    "    json.dump(log_collocations_vs_freq, f, indent = 4, ensure_ascii = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "Exception",
     "evalue": "Cannot load UDPipe model from file 'english-partut-ud-2.0-170801.udpipe'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-2b2f7f16a3d8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mclean_lemm_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_clean_lemm_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtexts_lenta\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'texts_3000'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlang\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'en'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Autotutor/improved_approach/colloc/calculate_colocations.py\u001b[0m in \u001b[0;36mget_clean_lemm_list\u001b[0;34m(corpus_list, lang)\u001b[0m\n\u001b[1;32m    195\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mlang\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"en\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m         \u001b[0mstopwords\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstopwords\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'english'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 197\u001b[0;31m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'english-partut-ud-2.0-170801.udpipe'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    198\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"NO AVAILABLE LANGUAGE SPECIFIED. EXIT\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Autotutor/improved_approach/colloc/ud_class.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, path)\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mufal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mudpipe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Cannot load UDPipe model from file '%s'\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mException\u001b[0m: Cannot load UDPipe model from file 'english-partut-ud-2.0-170801.udpipe'"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
