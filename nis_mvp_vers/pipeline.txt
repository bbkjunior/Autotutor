0) Заливаем тексты и отправляем их на обработку 
 
код - text_processing.get_text_map
пример - ноутбук get_texts_map

1) Пользователь заходит на сайт регистрируется получает свою учетную запись 
к которой будет привязана история его обучения

2) на основании ранее изученных текстов (ну то есть попросту исключая из оборота те тексты 
которые прошли в качестве тестирования знаний и те тексты которые прошли в качестве рекомендации) 
происходит автоматическая генерация тестовых текстов с вопросами типа "понятно-непонятно". 
Текст выбирается следующим образом - берем среднюю сложность грамматических фичей по всем распаршенным 
текстам находящихся в нашей БД, сортируем их и на вопросы отдаем топ 5 текстов по сложности 

код и пример - get_questions_to_most_complicated_texts.get_complicated_texts

3) на стороне веба выводятся тексты(моя штука отдает json), человек отвечает на вопрос понятно-непонятно, 
веб должен вернуть json с индексами текстов и внутри индексами предложений которые человек разметил

answer_dict = {
    "user_id":"pupkin_vasya",
    "answers": {0: OrderedDict([(0, True), (2, False), (5, False)]),
    17: OrderedDict([(0, False),
                 (2, False),
                 (4, False),
                 (8, True),
                 (10, False),
                 (12, False)]),
    26: OrderedDict([(0, False), (5, True), (7, True), (13, False)]),


4) получая этот json алгоритм рекомендации вступает в действие. 
Первым шагом он гшенерирует карту знаний ученика (это по сути ори разных датасета). 
Эти три датасета надо или создать в первый раз или сконкатенировать с уже существующими. 
Далее на сонвоании векторного пространства получаемого из этих датасетов алгоритм 
отрабатывает и производит рекомендацию

"recommended_text_1": {
        "text_ind": 35,
        "raw_text": "В Санкт-Петербурге скончался актер Сергей Салеев...."
    },
    "rec
Код
get_marked_datasets.generate_user_knowledge_database
knn_sklearn_recommendation.get_recommended_text_json

Пример  
get_answers_return_recommendation


5) get_recommended_text_json отдает json c рекомендованными и нерекомендованными текстами
Нужно вывести их пользователю и дать разметить на предмет который из каждой пары текстов сложнее
Размеченные тексты надо вернуть в виде json

recommendation_evaluate_dict = [
    {
        "recommended": {
            "marked_easier":True,
            "text_ind": 35
            "raw_text":......
        },
        "non_recommended": {
            "marked_easier":False,
            "text_ind": 39,
            "raw_text":.....
        }
    },

6) получаемый json идет в get_algo_accuracy, в котором считаются 
текущие показатели тончости отработавшего на данный момент алгоритма

Код и пример evaluate_algo_results.py

7) Далее надо реализовать кнопку "получить новые рекомендации" чтобы заново повторились шаги 2-5

НУЖНО БУДЕТ ГДЕ-ТО ХРАНИТЬ ИНДЕКСЫ ТЕКСТОВ КОТОРЫЕ УЖЕ ЛИБО ПОДАВАЛИСЬ НА ТЕСТИРОВАНИЕ ЛИБО РЕКОМЕНДОВАЛИСЬ, 
датасеты-карты знаний а также результаты шага рекомендации и собственно json текстов

При загрузке текста в сервис
Просто запускается алгоритм которые парсит текст и кладет карту текста в общую базу данных