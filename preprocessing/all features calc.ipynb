{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~–,»«'"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import re\n",
    "\n",
    "import os\n",
    "\n",
    "import operator\n",
    "\n",
    "import pymorphy2\n",
    "\n",
    "import nltk\n",
    "\n",
    "from string import punctuation\n",
    "full_punctuation = punctuation + \"–\" + \",\" + \"»\" + \"«\"\n",
    "full_punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>word</th>\n",
       "      <th>count_rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>а</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>аберрация</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>абстракция</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>аван</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>авангард</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index        word  count_rank\n",
       "0      0           а           2\n",
       "1      1   аберрация           2\n",
       "2      2  абстракция           1\n",
       "3      3        аван           1\n",
       "4      4    авангард           2"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sence = pd.read_csv(\"./for calculation/mult_sence.csv\")\n",
    "sence_dict = Series(df_sence.count_rank.values,index=df_sence.word).to_dict()\n",
    "df_sence.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'раисся'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def low(word):\n",
    "    return word.lower()\n",
    "low(\"Раисся\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Lemma</th>\n",
       "      <th>PoS</th>\n",
       "      <th>freq_lable</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>и</td>\n",
       "      <td>conj</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>в</td>\n",
       "      <td>pr</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>не</td>\n",
       "      <td>part</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>на</td>\n",
       "      <td>pr</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>я</td>\n",
       "      <td>spro</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0 Lemma   PoS  freq_lable\n",
       "0           0     и  conj           0\n",
       "1           1     в    pr           0\n",
       "2           2    не  part           0\n",
       "3           3    на    pr           0\n",
       "4           4     я  spro           0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_freq = pd.read_csv(\"./for calculation/freq_lables.csv\")\n",
    "df_freq['Lemma'] = df_freq['Lemma'].apply(low)\n",
    "freq_pos_dict = Series(df_freq.PoS.values,index=df_freq.Lemma).to_dict()\n",
    "freq_dict = Series(df_freq.freq_lable.values,index=df_freq.Lemma).to_dict()\n",
    "#df_freq = pd.read_csv(\"freq_lables.csv\")\n",
    "df_freq.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq_dict['по']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>orth</th>\n",
       "      <th>phon</th>\n",
       "      <th>sense</th>\n",
       "      <th>pos</th>\n",
       "      <th>gender</th>\n",
       "      <th>asp</th>\n",
       "      <th>dic_name</th>\n",
       "      <th>usg</th>\n",
       "      <th>etym_lang</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>аврал</td>\n",
       "      <td>АВР'АЛ</td>\n",
       "      <td>Общая работа на судне</td>\n",
       "      <td>сущ.</td>\n",
       "      <td>м.</td>\n",
       "      <td>None</td>\n",
       "      <td>Толковый словарь Кузнецова</td>\n",
       "      <td>None</td>\n",
       "      <td>англ.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>автокар</td>\n",
       "      <td>АВТОК'АР</td>\n",
       "      <td>автотележка.</td>\n",
       "      <td>сущ.</td>\n",
       "      <td>м.</td>\n",
       "      <td>None</td>\n",
       "      <td>Толковый словарь Кузнецова</td>\n",
       "      <td>None</td>\n",
       "      <td>англ.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>адаптер</td>\n",
       "      <td>АД'АПТЕР</td>\n",
       "      <td>= Звукосниматель.</td>\n",
       "      <td>сущ.</td>\n",
       "      <td>м.</td>\n",
       "      <td>None</td>\n",
       "      <td>Толковый словарь Кузнецова</td>\n",
       "      <td>None</td>\n",
       "      <td>англ.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>айсберг</td>\n",
       "      <td>'АЙСБЕРГ</td>\n",
       "      <td>о ком-л. не понятом, не разгаданном окружающи...</td>\n",
       "      <td>сущ.</td>\n",
       "      <td>м.</td>\n",
       "      <td>None</td>\n",
       "      <td>Толковый словарь Кузнецова</td>\n",
       "      <td>None</td>\n",
       "      <td>англ.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>акваланг</td>\n",
       "      <td>АКВАЛ'АНГ</td>\n",
       "      <td>Аппарат, состоящий из баллонов со сжатым возд...</td>\n",
       "      <td>сущ.</td>\n",
       "      <td>м.</td>\n",
       "      <td>None</td>\n",
       "      <td>Толковый словарь Кузнецова</td>\n",
       "      <td>None</td>\n",
       "      <td>англ.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       orth       phon                                              sense  \\\n",
       "0     аврал     АВР'АЛ                            Общая работа на судне     \n",
       "1   автокар   АВТОК'АР                                     автотележка.     \n",
       "2   адаптер   АД'АПТЕР                                = Звукосниматель.     \n",
       "3   айсберг   'АЙСБЕРГ   о ком-л. не понятом, не разгаданном окружающи...   \n",
       "4  акваланг  АКВАЛ'АНГ   Аппарат, состоящий из баллонов со сжатым возд...   \n",
       "\n",
       "    pos gender   asp                    dic_name   usg etym_lang  \n",
       "0  сущ.     м.  None  Толковый словарь Кузнецова  None     англ.  \n",
       "1  сущ.     м.  None  Толковый словарь Кузнецова  None     англ.  \n",
       "2  сущ.     м.  None  Толковый словарь Кузнецова  None     англ.  \n",
       "3  сущ.     м.  None  Толковый словарь Кузнецова  None     англ.  \n",
       "4  сущ.     м.  None  Толковый словарь Кузнецова  None     англ.  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_eng = pd.read_csv(\"./for calculation/eng_words.csv\", sep = ' ')\n",
    "eng_words = set(df_eng['orth'])\n",
    "df_eng.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "abs_suff={'аж',\n",
    " 'есть',\n",
    " 'ие',\n",
    " 'изм',\n",
    " 'изна',\n",
    " 'ина',\n",
    " 'ость',\n",
    " 'ота',\n",
    " 'ствo',\n",
    " 'ция',\n",
    " 'чина',\n",
    " 'щина',\n",
    " 'ёж','еж'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_lex_vector(lexema, POS):\n",
    "    #если слова нет в часотном словаре, значит оно скорее всего довольно редкое и признаем его относящ к категории 2\n",
    "    #если слово не заимствовано то признаем сложным 1 \n",
    "    sence_value, freq_value, eng_value, abstract= 0,2,1,0\n",
    "    if(lexema in sence_dict):\n",
    "        #print(lexema, \"found\")\n",
    "        sence_value = sence_dict[lexema]\n",
    "        \n",
    "        \n",
    "    if(lexema in freq_dict):\n",
    "        freq_value = freq_dict[lexema]\n",
    "    \n",
    "    if(lexema in eng_words):\n",
    "        eng_value = 0\n",
    "    \n",
    "    if (POS == \"NOUN\"):\n",
    "        for suff in abs_suff:\n",
    "            if (lexema.endswith(suff)):\n",
    "                abstract = 1\n",
    "\n",
    "    return [sence_value, freq_value, eng_value, abstract]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'INFN'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "morph = pymorphy2.MorphAnalyzer()\n",
    "morph.parse(\"делать\")[0].tag.POS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_line = \"Утром у здания Минкомсвязи разверзлась белизна на Тверской улице произошла драка. В ней погиб чемпион России по рукопашному бою Геннадий Павлов\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "\n",
    "iterables = [ [0,1,2], [0,1,2],[0,1],[0,1] ]\n",
    "poss_var = []\n",
    "for t in itertools.product(*iterables):\n",
    "    #print (t)\n",
    "    poss_var.append(str(t)[1:-1])\n",
    "print(len(poss_var))\n",
    "vocab_features_dict = OrderedDict.fromkeys(poss_var, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_features_dict['0, 2, 1, 0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def claculate_line_vocab_vector(text,morph, vocab_features_dict):\n",
    "    \"\"\"\n",
    "    составляем словарь лемматизированных существительных и словарь всех лемм \n",
    "    \"\"\"\n",
    "    #lex_vectors = []\n",
    "    lex_dict_check = {}\n",
    "    points_dict_for_database = {}\n",
    "    words = text.split()\n",
    "    for word in words:\n",
    "        parsed_word = morph.parse(word)[0]\n",
    "        lemma = parsed_word.normal_form      \n",
    "        pos = parsed_word.tag.POS\n",
    "        #print(lemma, pos)\n",
    "        vector = create_lex_vector(lemma, pos)\n",
    "        vector_id = str(vector)[1:-1]\n",
    "        \n",
    "        if(vector_id in vocab_features_dict):\n",
    "          vocab_features_dict [vector_id] += 1\n",
    "        else:\n",
    "            print(\"UNKNOWN VALUES {}\".format(vector_id))\n",
    "          #points_dict_for_database [ str(vector)[1:-1]] = 1\n",
    "        \n",
    "        \n",
    "        #lex_vectors.append(vector)\n",
    "        lex_dict_check[lemma] = vector\n",
    "    #print(lex_dict_check)\n",
    "\n",
    "claculate_line_vocab_vector(test_line, morph, vocab_features_dict)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "1. чистим текст от запятых и считаем ликс\n",
    "2. лемматизируем текст и считаем все остальное"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    sentences = nltk.sent_tokenize(text)\n",
    "    clean_sentence = []\n",
    "    #print(sentences)\n",
    "    for sentence in sentences:\n",
    "        words = sentence.split()\n",
    "        clean_text= ''\n",
    "        for word in words:\n",
    "            clean_word = ''\n",
    "            for char in word:\n",
    "                if char != \" \" and char not in full_punctuation:\n",
    "                    clean_word += char.lower()\n",
    "            clean_text += clean_word + ' '\n",
    "        clean_text = re.sub(' +', ' ', clean_text)\n",
    "        clean_text = clean_text.strip()\n",
    "        clean_sentence.append(clean_text)\n",
    "    return clean_sentence   \n",
    "\n",
    "def clean_file(file):\n",
    "    preprocessed_text = []\n",
    "    lines = 0\n",
    "    with open (file, \"r\", encoding = \"utf-8\") as file:\n",
    "        all_lines = file.readlines()\n",
    "        \n",
    "        for line in all_lines:\n",
    "            t = preprocess_text(line)\n",
    "            #print(t)\n",
    "            preprocessed_text.extend(t)\n",
    "            lines += 1\n",
    "\n",
    "    return preprocessed_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clean_txt = clean_file(\"text_8.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39.771679197994985\n"
     ]
    }
   ],
   "source": [
    "def calculate_lix_from_list_of_sentences(processed_text_sentences):\n",
    "        sentences_count = len(processed_text_sentences)\n",
    "        words_count = sum([len(line.split(' ')) for line in processed_text_sentences])\n",
    "        long_words_count = 0 #more than 6\n",
    "        for line in processed_text_sentences:\n",
    "            for word in line.split():\n",
    "                if len(word) > 6:\n",
    "                    long_words_count += 1\n",
    "        lix = words_count/ sentences_count + (long_words_count * 100) / words_count\n",
    "        print(lix)\n",
    "        \n",
    "calculate_lix_from_list_of_sentences(clean_txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def lemmatize_line(text,morph):\n",
    "    lemm_split_text = []\n",
    "    words = text.split()\n",
    "    for word in words:\n",
    "        parsed_word = morph.parse(word)[0]\n",
    "        lemma = parsed_word.normal_form      \n",
    "        lemm_split_text.append(lemma)\n",
    "    return ' '.join(lemm_split_text)\n",
    "\n",
    "def lemmatize_text_from_sent_list(sent_list):\n",
    "    lemm_text_lines = []\n",
    "    morph = pymorphy2.MorphAnalyzer()\n",
    "    for line in sent_list:\n",
    "        lemm_line = lemmatize_line(line, morph)\n",
    "        lemm_text_lines.append(lemm_line)\n",
    "    return lemm_text_lines\n",
    "lemm_text = lemmatize_text_from_sent_list(clean_txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5338345864661654"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def calculate_type_token_ratio(lemm_text_sentences):\n",
    "      all_words = []\n",
    "      for sentence in lemm_text_sentences:\n",
    "          words = sentence.split()\n",
    "          for word in words:\n",
    "              all_words.append(word)\n",
    "\n",
    "      unqie_words = set(all_words)\n",
    "      types = len(unqie_words)\n",
    "      tokens = len (all_words)\n",
    "\n",
    "      return types/tokens\n",
    "calculate_type_token_ratio (lemm_text)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "сделать словарь всех возможных значений сложности {0-1-2; 0-1-2; 0-1; 0-1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1]\n",
      "[0, 2]\n",
      "[1, 2]\n"
     ]
    }
   ],
   "source": [
    "for j, k in combinations([0,1,2], 2):\n",
    "    comb = [j,k]\n",
    "    print(comb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "iterables = [ [0,1,2], [0,1,2],[0,1],[0,1] ]\n",
    "poss_var = []\n",
    "for t in itertools.product(*iterables):\n",
    "    #print (t)\n",
    "    poss_var.append(str(t)[1:-1])\n",
    "#print(len(poss_var))\n",
    "vocab_features_dict_for_calc = OrderedDict.fromkeys(poss_var, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'odict_items' object does not support indexing",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-122-efa37b94155e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mvocvocab_features_dict_for_calcab_features_dict_for_calc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mOrderedDict\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfromkeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mposs_var\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mvocab_features_dict_for_calc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: 'odict_items' object does not support indexing"
     ]
    }
   ],
   "source": [
    "vocvocab_features_dict_for_calcab_features_dict_for_calc = OrderedDict.fromkeys(poss_var, 0)\n",
    "vocab_features_dict_for_calc.items()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('0, 0, 0, 0', 0.0),\n",
       "             ('0, 0, 0, 1', 0.0),\n",
       "             ('0, 0, 1, 0', 0.01),\n",
       "             ('0, 0, 1, 1', 0.01),\n",
       "             ('0, 1, 0, 0', 0.01),\n",
       "             ('0, 1, 0, 1', 0.0),\n",
       "             ('0, 1, 1, 0', 0.01),\n",
       "             ('0, 1, 1, 1', 0.0),\n",
       "             ('0, 2, 0, 0', 0.0),\n",
       "             ('0, 2, 0, 1', 0.0),\n",
       "             ('0, 2, 1, 0', 0.07),\n",
       "             ('0, 2, 1, 1', 0.01),\n",
       "             ('1, 0, 0, 0', 0.0),\n",
       "             ('1, 0, 0, 1', 0.0),\n",
       "             ('1, 0, 1, 0', 0.02),\n",
       "             ('1, 0, 1, 1', 0.0),\n",
       "             ('1, 1, 0, 0', 0.0),\n",
       "             ('1, 1, 0, 1', 0.0),\n",
       "             ('1, 1, 1, 0', 0.01),\n",
       "             ('1, 1, 1, 1', 0.0),\n",
       "             ('1, 2, 0, 0', 0.0),\n",
       "             ('1, 2, 0, 1', 0.0),\n",
       "             ('1, 2, 1, 0', 0.0),\n",
       "             ('1, 2, 1, 1', 0.0),\n",
       "             ('2, 0, 0, 0', 0.0),\n",
       "             ('2, 0, 0, 1', 0.0),\n",
       "             ('2, 0, 1, 0', 0.02),\n",
       "             ('2, 0, 1, 1', 0.0),\n",
       "             ('2, 1, 0, 0', 0.01),\n",
       "             ('2, 1, 0, 1', 0.0),\n",
       "             ('2, 1, 1, 0', 0.0),\n",
       "             ('2, 1, 1, 1', 0.0),\n",
       "             ('2, 2, 0, 0', 0.0),\n",
       "             ('2, 2, 0, 1', 0.0),\n",
       "             ('2, 2, 1, 0', 0.03),\n",
       "             ('2, 2, 1, 1', 0.0)])"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_features_dict_for_calc = OrderedDict.fromkeys(poss_var, 0)\n",
    "def calculate_vocab_feaures_from_sent_list(lemm_sent, vocab_features_dict):\n",
    "    \n",
    "    for sent in lemm_sent:\n",
    "        claculate_line_vocab_vector(sent,morph, vocab_features_dict)\n",
    "    #print(vocab_features_dict.values())    \n",
    "    all_vals = vocab_features_dict.values()\n",
    "\n",
    "    for ind in range(len(vocab_features_dict)):\n",
    "        el = list(vocab_features_dict.keys())[ind]\n",
    "        vocab_features_dict[el] /= sum(all_vals)\n",
    "calculate_vocab_feaures_from_sent_list(lemm_text, vocab_features_dict_for_calc)\n",
    "\n",
    "vocab_features_dict"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
